CODES

Copy files to read
hadoop fs -copyFromLocal emp.csv pig/emp.csv 

Load Data

 A = load '/user/root/pig/emp.csv' using PigStorage(',') as (eid:int,ename:chararray,epos:chararray,esal:int,ecom:int,edpno:int);
Dump A;
A2 = load '/user/root/pig/emp.csv’;
describe A2;


Aggregate (by row)

B = filter A by edpno==2;
B2 = filter A by edpno==20 and esal<1000,
C = limit B 3;
D = order C by esal desc;

Store Data
store D into '/pig/pigout1’ using PigStorage(',’);

Transform (by column)

Select existing column
E = foreach A generate eid;

Create new column
F = foreach A generate *,esal*5 as Incentive;

Transform columns
G = foreach A generate SUBSTRING(ename,0,4);


Advanced codes

H = foreach A generate $0,$1;
I = group A by edpno;
J = foreach I generate group as edpno, COUNT($1) as count;
K = foreach A generate MAX(A.esal) as maxsal,MIN(A.esal) as minsal, SUM(A.esal) as sumsal, COUNT($1) as count;
L = group A by (edpno, epos)

SPLIT A into B if edpno==10, C if edpno==20, D if epos=='MANAGER';

Joins

A = load '/emp.csv' using PigStorage(',') as (eid:int,ename:chararray,epos:chararray,esal:int,ecom:int,edpno:int);
B = load '/dept.csv' using PigStorage(',') as (edpno:int,epos:chararray,ecity:chararray);
C = JOIN A by edpno,B by edpno;
D = foreach C generate A::eid,B::epos;
E = JOIN A by edpno RIGHT OUTER, B by edpno;

