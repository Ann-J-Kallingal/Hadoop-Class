# HIVE INSTALLATION

#downloading hive

cd course/softwares
#to download hive 
wget https://apache.osuosl.org/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz
#to unzip the file
tar -xzf apache-hive-3.1.2-bin.tar.gz
mv apache-hive-3.1.2-bin hive


#setting the path 

nano ~/.bashrc
export HIVE_HOME=$HOME/Desktop/course/softwares/hive
export PATH=$PATH:$HIVE_HOME/sbin:$HIVE_HOME/bin
export CLASSPATH=$CLASSPATH:$HADOOP_HOME/lib/*:$HIVE_HOME/lib/*
source ~/.bashrc

cd $HIVE_HOME/conf
nano hive-env.sh
export HADOOP_HOME=$HOME/Desktop/course/softwares/hadoop-3.3.4

# Metastore - Apache Derby configuration

#downloading derby

cd course/softwares
wget http://archive.apache.org/dist/db/derby/db-derby-10.4.2.0/db-derby-10.4.2.0-bin.tar.gz
tar zxvf db-derby-10.4.2.0-bin.tar.gz
mv db-derby-10.4.2.0-bin derby


nano ~/.bashrc
export DERBY_HOME=$HOME/Desktop/course/softwares/derby
export PATH=$PATH:$DERBY_HOME/bin
export CLASSPATH=$CLASSPATH:$DERBY_HOME/lib/derby.jar:$DERBY_HOME/lib/derbytools.jar
source ~/.bashrc

mkdir $DERBY_HOME/data

# Configure Derby for Hive
cd $HIVE_HOME/conf
nano hive-site.xml
<configuration>

   <property>
   	<name>javax.jdo.option.ConnectionURL</name>
   	<value>jdbc:derby:;databaseName=metastore_db;create=true</value>
    <description>JDBC connect string for a JDBC metastore </description>
   </property>
   
</configuration>

nano jpox.properties

javax.jdo.PersistenceManagerFactoryClass =

org.jpox.PersistenceManagerFactoryImpl
org.jpox.autoCreateSchema = false
org.jpox.validateTables = false
org.jpox.validateColumns = false
org.jpox.validateConstraints = false
org.jpox.storeManagerType = rdbms
org.jpox.autoCreateSchema = true
org.jpox.autoStartMechanismMode = checked
org.jpox.transactionIsolation = read_committed
javax.jdo.option.DetachAllOnCommit = true
javax.jdo.option.NontransactionalRead = true
javax.jdo.option.ConnectionDriverName = org.apache.derby.jdbc.ClientDriver
javax.jdo.option.ConnectionURL = jdbc:derby://hadoop1:1527/metastore_db;create = true
javax.jdo.option.ConnectionUserName = APP
javax.jdo.option.ConnectionPassword = mine

# Setup Hive in HDFS
$HADOOP_HOME/bin/hadoop fs -mkdir /tmp 
$HADOOP_HOME/bin/hadoop fs -mkdir /user/hive/warehouse
$HADOOP_HOME/bin/hadoop fs -chmod g+w /tmp 
$HADOOP_HOME/bin/hadoop fs -chmod g+w /user/hive/warehouse

cd $HIVE_HOME
bin/schematool -initSchema -dbType derby
bin/hive


#codes

#creating database

hive
show databases;
create database if not exists bda01;
Use bda01;

#Check location from hdfs
hadoop fs -ls /user/hive/warehouse

#creating tables
create table if not exists emp(empno int, ename string, sal float, comm float, dpno int) row format delimited fields terminated by ',’;
describe emp;

#loading data 
load data local inpath '/home/user/data/emp.csv' into table emp;

#display
Select * from emp;

#creating external table
create external table  ext_emp1(empno int, ename string, sal float, comm float, dpno int) row format delimited fields terminated by ',’ location '/user/data/emp’;
While giving path we have to give only directory path not file name
Here, table will be in given hdfs path.

create external table  ext_emp2(empno int, ename string, sal float, comm float, dpno int) row format delimited fields terminated by ‘,’;
Table will be stored under /user/hive/warehouse/emp.db/ext_emp2/emp

load data local inpath '/home/ann007/Desktop/empdata' into table ext_emp2;

#Partioning
set hive.exec.dynamic.partition.mode;
set hive.exec.dynamic.partition.mode=nonstrict;

create external table emp_dept (empno int, ename string, sal float, comm float) partitioned by (dpno int) row format delimited fields terminated by ',’;
insert into table emp_dept partition(dpno) select * from emp;

#Checking
hadoop fs -ls /user/hive/warehouse/emp.db

#Bucketing
create table dept_buckk(empno int, ename string, sal float, comm float, dpno int)  clustered by (dpno) into 3 buckets row format delimited fields terminated by ‘,’;
set hive.enforce.bucketing = true;


